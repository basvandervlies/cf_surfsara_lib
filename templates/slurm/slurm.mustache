# slurm.conf file generated by CFEngine
#
# See the slurm.conf man page for more information.
#
ClusterName={{{vars.scl.slurm.ClusterName}}}
SlurmctldHost={{{vars.scl.slurm.ControlMachine}}}
#
SlurmUser={{{vars.slurm.user}}}
SlurmctldPort={{{vars.scl.slurm.SlurmctldPort}}}
SlurmdPort={{{vars.scl.slurm.SlurmdPort}}}

AuthType={{{vars.scl.slurm.AuthType}}}

SwitchType=switch/none
MpiDefault={{{vars.scl.slurm.MpiDefault}}}

StateSaveLocation={{{vars.slurm.spool_dir}}}/checkpoint
SlurmdSpoolDir={{{vars.slurm.spool_dir}}}/slurmd

SlurmctldLogFile={{{vars.slurm.log_dir}}}/slurmctld.log
SlurmdLogFile={{{vars.slurm.log_dir}}}/slurmd.log

SlurmctldPidFile={{{vars.scl.slurm.pid_dir}}}/slurmctld.pid
SlurmdPidFile={{{vars.scl.slurm.pid_dir}}}/slurmd.pid

PluginDir={{{vars.slurm.plugin_dir}}}
TmpFS={{{vars.scl.slurm.tmpfs}}}

#
# job steps/allocation parameters
#
JobContainerType={{{vars.scl.slurm.JobContainerType}}}
#ProctrackType=proctrack/pgid
ProctrackType=proctrack/cgroup

ReturnToService=1
#UnkillableStepTimeout=600
#UnkillableStepProgram="scontrol update NodeName=$(hostname -s) State=down Reason=hung_proc"
#
# Max settings
#
MaxJobCount=100000
MaxArraySize=1001

#
#
# TIMERS
InactiveLimit={{{vars.scl.slurm.InactiveLimit}}}
KillWait={{{vars.scl.slurm.KillWait}}}
MessageTimeout={{{vars.scl.slurm.MessageTimeout}}}
MinJobAge={{{vars.scl.slurm.MinJobAge}}}
SlurmctldTimeout={{{vars.scl.slurm.SlurmctldTimeout}}}
SlurmdTimeout={{{vars.scl.slurm.SlurmdTimeout}}}
WaitTime={{{vars.scl.slurm.WaitTime}}}
UnkillableStepTimeout={{{vars.scl.slurm.UnkillableStepTimeout}}}

## slurmctld parameter section
{{#vars.scl.slurm.slurmctld_settings}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.slurmctld_settings}}

## Sched section
{{#vars.scl.slurm.scheduling_section.comment}}
# {{{.}}}
{{/vars.scl.slurm.scheduling_section.comment}}
SchedulerParameters={{#vars.scl.slurm.scheduling_section.parameters}}{{{.}}},{{/vars.scl.slurm.scheduling_section.parameters}}
{{#vars.scl.slurm.scheduling_section.settings}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.scheduling_section.settings}}


# LOGGING
DebugFlags={{#vars.scl.slurm.DebugFlags}}{{{.}}},{{/vars.scl.slurm.DebugFlags}}
SlurmctldDebug={{{vars.scl.slurm.SlurmctldDebug}}}
SlurmdDebug={{{vars.scl.slurm.SlurmdDebug}}}
JobCompType=jobcomp/none
JobCompLoc=/tmp/slurm_job_completion.txt
#
# ACCOUNTING
JobAcctGatherType=jobacct_gather/linux
JobAcctGatherFrequency=30
JobAcctGatherParams=UsePss
{{#vars.scl.slurm.acct_gather_section}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.acct_gather_section}}
#
{{#vars.scl.slurm.accounting_storage_section}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.accounting_storage_section}}
GresTypes={{{vars.scl.slurm.GresTypes}}}
#
# COMPUTE NODES
# control node

## Plugins
TopologyPlugin=topology/tree

# SURFsara
MailProg=/usr/bin/mail

# Priority
{{#vars.scl.slurm.priority_section}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.priority_section}}
#
# Task plugin
{{#vars.scl.slurm.taskplugin_section}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.taskplugin_section}}

## Launch Parameters for job launch plugin
{{#vars.scl.slurm.launch_parameters}}
LaunchParameters={{{options}}}
{{/vars.scl.slurm.launch_parameters}}


## launching salloc will automatically start an srun process with InteractiveStepOptions
# to launch a terminal on a node in the job allocation.
{{#vars.scl.slurm.interactive_step_options}}
InteractiveStepOptions={{{options}}}
{{/vars.scl.slurm.interactive_step_options}}


# Prolog and Epilog scripts
Epilog={{{vars.scl.slurm.Epilog}}}
Prolog={{{vars.scl.slurm.Prolog}}}
PrologEpilogTimeout={{{vars.scl.slurm.PrologEpilogTimeout}}}
PrologFlags={{{vars.scl.slurm.PrologFlags}}}
PrologSlurmctld={{{vars.scl.slurm.PrologSlurmctld}}}
{{#vars.scl.slurm.prolog_section}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.prolog_section}}

# NHC health check
{{#vars.scl.slurm.health_section}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.health_section}}

## Power save section parameters
# https://slurm.schedmd.com/power_save.html
#{{#vars.scl.slurm.powersave_section}}
#{{{@}}}={{{.}}}
#{{/vars.scl.slurm.powersave_section}}

# Reboot
RebootProgram=/sbin/reboot

# No default section hold keywords that do nt have a default value
{{#vars.scl.slurm.no_default_section}}
{{{@}}}={{{.}}}
{{/vars.scl.slurm.no_default_section}}

# PARTITIONS
EnforcePartLimits=ALL
{{#vars.scl.slurm.partition_section}}
PartitionName={{{name}}} {{#settings}}{{{@}}}={{{.}}} {{/settings}}
{{/vars.scl.slurm.partition_section}}

# Licenses
Licenses={{#vars.scl.slurm.licenses_section}}{{{.}}},{{/vars.scl.slurm.licenses_section}}

# NODE configuration
{{#vars.scl.slurm.nodes_section}}
NodeName={{{Name}}} {{#settings}}{{{@}}}={{{.}}} {{/settings}}
{{/vars.scl.slurm.nodes_section}}

{{^classes.SLURM_CONFIGLESS}}
# Include section only for NON slurm configless configuration
    {{#vars.scl.slurm.include_files}}
Include {{{.}}}
    {{/vars.scl.slurm.include_files}}
{{/classes.SLURM_CONFIGLESS}}
